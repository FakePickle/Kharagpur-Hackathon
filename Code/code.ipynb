{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (0.11.5)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Collecting numpy>=1.17 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vikra\\onedrive\\desktop\\kharagpur-hackathon\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.1 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.1 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.0-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "   ---------------------------------------- 0.0/43.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/43.6 MB 8.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.5/43.6 MB 9.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.8/43.6 MB 10.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.4/43.6 MB 10.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.8/43.6 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.2/43.6 MB 11.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.5/43.6 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.1/43.6 MB 11.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.5/43.6 MB 11.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 24.1/43.6 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.5/43.6 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.1/43.6 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.5/43.6 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 33.8/43.6 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.4/43.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.8/43.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.4/43.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/43.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.6/43.6 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.6 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.7/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 11.3 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, threadpoolctl, sympy, setuptools, safetensors, pyyaml, numpy, networkx, MarkupSafe, idna, fsspec, filelock, certifi, scipy, requests, jinja2, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2024.12.14 filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.1 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.1 pyyaml-6.0.2 requests-2.32.3 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.0 sentence_transformers-3.3.1 setuptools-75.8.0 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.1 typing-extensions-4.12.2 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk pdfplumber sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_26660\\1032529567.py:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  file_path = \"..\\Dataset\\Papers\\P001.pdf\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leveraging Clustering Techniques for Enhanced\n",
      "Drone Monitoring and Position Estimation\n",
      "Abstract\n",
      "Dronetrackingandlocalizationareessentialforvariousapplications,including\n",
      "managingdroneformationsandimplementinganti-dronestrategies. Pinpointing\n",
      "andmonitoringdronesinthree-dimensionalspaceisdifficult,particularlywhen\n",
      "tryingtocapturethesubtlemovementsofsmalldronesduringrapidmaneuvers.\n",
      "Thisinvolvesextractingfaintsignalsfromvariedflightsettingsandmaintaining\n",
      "alignmentdespiteswiftactions. Typically,camerasandLiDARsystemsareused\n",
      "torecordthepathsofdrones. However,theyencounterchallengesincategorizing\n",
      "dronesandestimatingtheirpositionsaccurately. Thisreportprovidesanoverview\n",
      "ofanapproachnamedCL-Det.Itusesaclustering-basedlearningdetectionstrategy\n",
      "totrackandestimatethepositionofdronesusingdatafromtwotypesofLiDAR\n",
      "sensors: LivoxAviaandLiDAR360. ThismethodmergesdatafrombothLiDAR\n",
      "sources to accurately determine the drone’s location in three dimensions. The\n",
      "methodbeginsbysynchronizingthetimecodesofthedatafromthetwosensors\n",
      "andthenisolatesthepointclouddatafortheobjectsofinterest(OOIs)fromthe\n",
      "environmental data. A Density-Based Spatial Clustering of Applications with\n",
      "Noise(DBSCAN)methodisappliedtoclustertheOOIpointclouddata,andthe\n",
      "centerpointofthemostprominentclusteristakenasthedrone’slocation. The\n",
      "techniquealsoincorporatespastpositionestimatestocompensateforanymissing\n",
      "information.\n",
      "1 Introduction\n",
      "Unmannedaerialvehicles(UAVs),commonlyreferredtoasdrones,havegainedprominenceand\n",
      "significantlyinfluenceareaslikelogistics,imaging,andemergencyresponse,offeringsubstantial\n",
      "advantagestosociety. However,thebroadadoptionandsophisticatedfeaturesofcompact,off-the-\n",
      "shelfdroneshavecreatedintricatesecurityissuesthatextendbeyondconventionalrisks.\n",
      "Recentyearshavewitnessedasurgeinresearchonanti-UAVsystems. Presentanti-UAVmethods\n",
      "predominantlyutilizevisual,radar,andradiofrequency(RF)technologies. Despitethesestrides,\n",
      "recognizingdronesposesaconsiderablehurdleforsensorslikecameras,particularlywhendrones\n",
      "areatsignificantaltitudesorinchallengingvisualenvironments. Thesemethodsusuallyfailtospot\n",
      "smalldronesbecauseoftheirminimalsize, whichleadstoadecreasedradarcross-sectionanda\n",
      "lessnoticeablevisualpresence. Furthermore,currentanti-UAVstudiesprimarilyfocusondetecting\n",
      "objectsandtrackingthemintwodimensions,overlookingthecrucialelementofestimatingtheir\n",
      "3Dpaths. Thisomissionsignificantlyrestrictstheeffectivenessofanti-UAVsystemsinpractical,\n",
      "real-worldcontexts.\n",
      "Ourproposedsolution,adetectionmethodbasedonclusteringlearning(CL-Det),usesthestrengths\n",
      "of both Livox Avia and LiDAR 360 to improve the tracking and position estimation of UAVs.\n",
      "Initially,thetimestampsfromtheLivoxAviaandLiDAR360dataarealignedtomaintaintemporal\n",
      "consistency. By examining the LiDAR data, which contains the spatial coordinates of objects at\n",
      "specifictimes,andcomparingthesetotheactualrecordedpositionsofthedroneatthosetimes,the\n",
      "drone’slocationwithintheLiDARpointclouddataiseffectivelypinpointed. Thepointcloudfor\n",
      ".\n",
      "objectsofinterest(OOIs)isthenisolatedfromtheenvironmentaldata. ThepointcloudoftheOOIs\n",
      "isgroupedusingtheDBSCANalgorithm,andthecentralpointofthelargestclusterisdesignatedas\n",
      "theUAV’sposition. Moreover,radardataalsofacessignificantchallengesduetomissinginformation.\n",
      "Tomitigatepotentialdatadeficiencies,pastestimationsareemployedtosupplementmissingdata,\n",
      "therebymaintainingtheconsistencyandprecisionofUAVtracking.\n",
      "2 Methodology\n",
      "This section details the methodology employed to ascertain the drone’s spatial position utilizing\n",
      "informationfromLiDAR360andLivoxAviasensors. Thestrategyintegratesdatafrombothsensor\n",
      "typestoachieveprecisepositioncalculations.\n",
      "2.1 DataSources\n",
      "Thefollowingmodalitiesofdatawereutilized:\n",
      "• Doublefisheyecameravisualimages\n",
      "• LivoxMid-360(LiDAR360)3Dpointclouddata\n",
      "• LivoxAvia3Dpointclouddata\n",
      "• Millimeter-waveradar3Dpointclouddata\n",
      "Only14outof59testsequenceshavenon-zeroradarvalues;therefore,theradardatasetisexcluded\n",
      "fromthisworkduetodataavailabilityissues. Twoprimarysensortypesareemployed: LiDAR360\n",
      "andLivoxAvia,bothofwhichsupply3Dpointclouddatacrucialforidentifyingthedrone’slocation.\n",
      "Thedetaileddatadescriptionsareoutlinedasfollows:\n",
      "• LiDAR 360 offers a complete 360-degree view with 3D point cloud data. This dataset\n",
      "encompassesenvironmentaldetailsandotherobservableobjects.\n",
      "• LivoxAviadeliversfocused3Dpointclouddataatspecifictimestamps,typicallyindicating\n",
      "theoriginpointorthedrone’sposition.\n",
      "2.2 Algorithm\n",
      "Foreverysequence, correspondingpositionsarerecordedatspecifictimestamps. Theprocedure\n",
      "givesprecedencetoLiDAR360data,usingLivoxAviadataasabackupiftheformerisnotavailable.\n",
      "Ifneithersourceisaccessible,thepositionisestimatedusinghistoricalaverages.\n",
      "2.2.1 LiDAR360DataProcessing\n",
      "• SeparationofPoints: TheLiDAR360dataisvisuallyexaminedtoclassifyareasintotwo\n",
      "zones: environmentandnon-environmentzones.\n",
      "• RemovalofEnvironmentPoints: Allpointswithintheenvironmentzonearedeemedpart\n",
      "ofthesurroundingsandarethusexcludedfromthedataset. Afterremovingenvironment\n",
      "points,itisobservedthattheremainingnon-environmentpointsimplythedroneposition.\n",
      "• Clustering:TheDBSCANclusteringalgorithmisappliedtotheremainingpointstodiscern\n",
      "distinctclusters.\n",
      "• ClusterSelection: Themostextensivenon-environmentclusterischosenastherepresenta-\n",
      "tivegroupofpointsthatcorrespondtothedrone.\n",
      "• MeanPositionCalculation: Thedrone’spositionisdeterminedbycalculatingthemeanof\n",
      "theselectedcluster,representedby(x,y,z)coordinates.\n",
      "2.2.2 LivoxAviaDataProcessing\n",
      "• RemovalofNoise: Pointswithcoordinates(0,0,0)areeliminatedastheyareregardedas\n",
      "noise.\n",
      "• MeanPositionCalculation: Themeanoftheresidualpointsiscomputedtoascertainthe\n",
      "drone’spositionin(x,y,z)coordinates.\n",
      "2\n",
      "2.2.3 FallbackMethod\n",
      "WhenneitherLiDAR360norLivoxAviadataisavailable,theaveragelocationofthedronederived\n",
      "fromtrainingdatasetsisused. Theaveragegroundtruthposition(x,y,z)fromalltrainingdatasets\n",
      "estimatesthedronegroundtruthposition,whichis(0.734,-9.739,33.353).\n",
      "2.3 ImplementationDetails\n",
      "TheprogramfetchesLiDAR360orLivoxAviadatafromthenearesttimestampforeachsequence,\n",
      "asindicatedinthetestdataset. ClusteringisexecutedusingtheDBSCANalgorithmwithappro-\n",
      "priateparameterstoguaranteestrongclustering. Visualinspectionisemployedforthepreliminary\n",
      "separationofpoints,ensuringanaccuratecategorizationofenvironmentpoints.\n",
      "The implementation was conducted on a Lenovo IdeaPad Slim 5 Pro (16\") running Windows 11\n",
      "with an AMD Ryzen 7 5800H CPU and 16GB DDR4 RAM. The analysis was carried out in a\n",
      "JupyterNotebookenvironmentusingPython3.10. Forclustering,theDBSCANalgorithmfromthe\n",
      "Scikit-Learnlibrarywasutilized. TheDBSCANalgorithmwasconfiguredwithanepsilon(eps)\n",
      "valueof2andaminimumnumberofpoints(minPts)setto1.\n",
      "3 Results\n",
      "ThealgorithmachievedaposeMSElossof120.215andaclassificationaccuracyof0.322. Table1\n",
      "presentstheevaluationresultscomparedtootherteams.\n",
      "Table1: Evaluationresultsontheleaderboard\n",
      "Team ID PoseMSE(↓) Accuracy(↑)\n",
      "SDUCZS 58198 2.21375 0.8136\n",
      "GaofenLab 57978 7.299575 0.3220\n",
      "sysutlt 57843 24.50694 0.3220\n",
      "casetrous 58233 56.880267 0.2542\n",
      "NTU-ICG(ours) 58268 120.215107 0.3220\n",
      "MTC 58180 189.669428 0.2724\n",
      "gzist 56936 417.396317 0.2302\n",
      "4 Conclusions\n",
      "Thispaperintroducesaclustering-basedlearningmethod,CL-Det,whichemploysadvancedcluster-\n",
      "ingtechniquessuchasK-MeansandDBSCANfordronedetectionandpositionestimationusing\n",
      "LiDARdata. Theapproachguaranteesdependableandprecisedronepositionestimationbyutilizing\n",
      "multi-sensordataandrobustclusteringmethods. Fallbackmechanismsareinplacetoensurecon-\n",
      "tinuouspositionestimationevenwhenprimarysensordataisabsent. Throughthoroughparameter\n",
      "optimizationandcomparativeassessment,theproposedmethod’seffectiveperformanceindrone\n",
      "trackingandpositionestimationisdemonstrated.\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"  # Extract text page by page\n",
    "    return text\n",
    "\n",
    "file_path = \"..\\Dataset\\Papers\\P001.pdf\"\n",
    "pdf_text = extract_text_from_pdf(file_path)\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Paragraphs with No Full Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: True\n",
      "Paragraph: Leveraging Clustering Techniques for Enhanced\n",
      "Drone Monitoring and Position Estimation\n",
      "Abstract\n",
      "Dronetrackingandlocalizationareessentialforvariousapplications,including\n",
      "managingdroneformationsandimple...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\vikra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Function to validate paragraphs\n",
    "def validate_paragraphs(paragraphs, word_threshold=50):\n",
    "    results = []\n",
    "    for para in paragraphs:\n",
    "        sentences = sent_tokenize(para)  # Tokenize into sentences\n",
    "        if len(sentences) == 0:  # No sentences detected\n",
    "            results.append((para, False))  # Invalid paragraph\n",
    "            continue\n",
    "        avg_words_per_sentence = len(para.split()) / len(sentences)\n",
    "        results.append((para, avg_words_per_sentence <= word_threshold))\n",
    "    return results\n",
    "\n",
    "# Split the extracted text into paragraphs\n",
    "paragraphs = pdf_text.split(\"\\n\\n\")  # Assuming double newlines separate paragraphs\n",
    "validation_results = validate_paragraphs(paragraphs)\n",
    "\n",
    "# Display validation results\n",
    "for para, is_valid in validation_results:\n",
    "    print(f\"VALID: {is_valid}\\nParagraph: {para[:200]}...\\n\")  # Print first 200 chars for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title and Abstract Misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikra\\OneDrive\\Desktop\\Kharagpur-Hackathon\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\vikra\\OneDrive\\Desktop\\Kharagpur-Hackathon\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vikra\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title and Abstract are aligned (Similarity Score: 0.63)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import sentence_transformers\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Title and Abstract\n",
    "title = \"Leveraging Clustering Techniques for Enhanced Drone Monitoring and Position Estimation\"\n",
    "abstract = \"\"\"\n",
    "Drone tracking and localization are essential for various applications, including managing drone formations and implementing anti-drone strategies. Pinpointing and monitoring drones in three-dimensional space...\n",
    "\"\"\"  # (Complete abstract extracted earlier)\n",
    "\n",
    "# Check title-abstract alignment\n",
    "def check_title_abstract_alignment(title, abstract, threshold=0.5):\n",
    "    title_embedding = model.encode(title, convert_to_tensor=True)\n",
    "    abstract_embedding = model.encode(abstract, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(title_embedding, abstract_embedding)\n",
    "    return similarity.item() >= threshold, similarity.item()\n",
    "\n",
    "# Perform the check\n",
    "is_aligned, similarity_score = check_title_abstract_alignment(title, abstract)\n",
    "print(f\"Title and Abstract are {'aligned' if is_aligned else 'misaligned'} (Similarity Score: {similarity_score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
