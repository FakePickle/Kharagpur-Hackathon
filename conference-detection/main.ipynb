{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEYWORDS DETECTION FOR CONFERENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining the Convergence of Denoising Diffusion Probabilistic\n",
      "Models: A Quantitative Analysis\n",
      "Abstract\n",
      "Deep generative models, particularly diffusion models, are a significant family within deep learning. This study\n",
      "provides a precise upper limit for the Wasserstein distance between a learned distribution by a diffusion model\n",
      "and the target distribution. In contrast to earlier research, this analysis does not rely on presumptions regarding\n",
      "the learned score function. Furthermore, the findings are applicable to any data-generating distributions within\n",
      "restricted instance spaces, even those lacking a density relative to the Lebesgue measure, and the upper limit is not\n",
      "exponentially dependent on the ambient space dimension. The primary finding expands upon recent research by\n",
      "Mbacke et al. (2023), and the proofs presented are fundamental.\n",
      "1 Introduction\n",
      "Diffusion models, alongside generative adversarial networks and variational autoencoders (V AEs), are among the most influential\n",
      "families of deep generative models. These models have demonstrated remarkable empirical results in generating images and audio,\n",
      "as well as in various other applications.\n",
      "Two primary methods exist for diffusion models: denoising diffusion probabilistic models (DDPMs) and score-based generative\n",
      "models (SGMs). DDPMs incrementally convert samples from the desired distribution into noise via a forward process, while\n",
      "simultaneously training a backward process to reverse this transformation, enabling the creation of new samples. Conversely, SGMs\n",
      "employ score-matching methods to approximate the score function of the data-generating distribution, subsequently generating new\n",
      "samples through Langevin dynamics. Recognizing that real-world distributions might lack a defined score function, adding varying\n",
      "noise levels to training samples to encompass the entire instance space and training a neural network to concurrently learn the score\n",
      "function for all noise levels has been proposed.\n",
      "Although DDPMs and SGMs may initially seem distinct, it has been demonstrated that DDPMs implicitly approximate the score\n",
      "function, with the sampling process resembling Langevin dynamics. Moreover, a unified perspective of both methods using stochastic\n",
      "differential equations (SDEs) has been derived. The SGM can be viewed as a discretization of Brownian motion, and the DDPM as a\n",
      "discretization of an Ornstein-Uhlenbeck process. Consequently, both DDPMs and SGMs are commonly referred to as SGMs in the\n",
      "literature. This explains why prior research investigating the theoretical aspects of diffusion models has adopted the score-based\n",
      "framework, necessitating assumptions about the effectiveness of the learned score function.\n",
      "In this research, a different strategy is employed, applying methods created for V AEs to DDPMs, which can be viewed as hierarchical\n",
      "V AEs with fixed encoders. This method enables the derivation of quantitative, Wasserstein-based upper bounds without making\n",
      "assumptions about the data distribution or the learned score function, and with simple proofs that do not need the SDE toolkit.\n",
      "Furthermore, the bounds presented here do not involve any complex discretization steps, as the forward and backward processes are\n",
      "considered discrete-time from the beginning, rather than being viewed as discretizations of continuous-time processes.\n",
      "1.1 Related Works\n",
      "There has been an increasing amount of research aimed at providing theoretical findings on the convergence of SGMs. However,\n",
      "these studies frequently depend on restrictive assumptions regarding the data-generating distribution, produce non-quantitative upper\n",
      "bounds, or exhibit exponential dependencies on certain parameters. This work successfully circumvents all three of these limitations.\n",
      "Some bounds are based on very restrictive assumptions about the data-generating distribution, such as log-Sobolev inequalities,\n",
      "which are unrealistic for real-world data distributions. Furthermore, some studies establish upper bounds on the Kullback-Leibler\n",
      "(KL) divergence or the total variation (TV) distance between the data-generating distribution and the distribution learned by the\n",
      "diffusion model; however, unless strong assumptions are made about the support of the data-generating distribution, KL and TV\n",
      "reach their maximum values. Such assumptions arguably do not hold for real-world data-generating distributions, which are widely\n",
      "believed to satisfy the manifold hypothesis. Other work establishes conditions under which the support of the input distribution\n",
      "is equal to the support of the learned distribution, and generalizes the bound to all f-divergences. Assuming L2 accurate score\n",
      "estimation, some establish Wasserstein distance upper bounds under weaker assumptions on the data-generating distribution, but\n",
      "their Wasserstein-based bounds are not quantitative. Quantitative Wasserstein distance upper bounds under the manifold hypothesis\n",
      "have been derived, but these bounds exhibit exponential dependencies on some of the problem parameters.\n",
      "1.2 Our contributions\n",
      "In this study, strong assumptions about the data-generating distribution are avoided, and a quantitative upper bound on the Wasserstein\n",
      "distance is established without exponential dependencies on problem parameters, including the ambient space dimension. Moreover,\n",
      "a common aspect of the aforementioned studies is that their bounds are contingent on the error of the score estimator. According to\n",
      "some, providing precise guarantees for the estimation of the score function is challenging, as it necessitates an understanding of the\n",
      "non-convex training dynamics of neural network optimization, which is currently beyond reach. Therefore, upper bounds are derived\n",
      "without making assumptions about the learned score function. Instead, the bound presented here is dependent on a reconstruction\n",
      "loss calculated over a finite independent and identically distributed (i.i.d.) sample. Intuitively, a loss function is defined, which\n",
      "quantifies the average Euclidean distance between a sample from the data-generating distribution and the reconstruction obtained by\n",
      "sampling noise and passing it through the backward process (parameterized by ˘03b8). This method is inspired by previous work on\n",
      "V AEs.\n",
      "This approach offers numerous benefits: it does not impose restrictive assumptions on the data-generating distribution, avoids\n",
      "exponential dependencies on the dimension, and provides a quantitative upper bound based on the Wasserstein distance. Furthermore,\n",
      "this method benefits from utilizing very straightforward and basic proofs.\n",
      "2 Preliminaries\n",
      "Throughout this paper, lowercase letters are used to represent both probability measures and their densities with respect to the\n",
      "Lebesgue measure, and variables are added in parentheses to enhance readability (e.g., q(xt|xt−1)to denote a time-dependent\n",
      "conditional distribution). An instance space X, which is a subset of RDwith the Euclidean distance as the underlying metric, and\n",
      "a target data-generating distribution µ∈M+\n",
      "1(X)are considered. Note that it is not assumed that µhas a density with respect to\n",
      "the Lebesgue measure. Additionally, || · || represents the Euclidean (L2) norm, and Ep(x)is used as shorthand for Ex∼p(x). Given\n",
      "probability measures p, q∈M+\n",
      "1(X)and a real number k >1, the Wasserstein distance of order kis defined as (Villani, 2009):\n",
      "Wk(p, q) = inf\n",
      "γ∈Γ(p,q)\u0012Z\n",
      "X×X||x−y||kdγ(x, y)\u00131/k\n",
      ",\n",
      "where Γ(p, q)denotes the set of couplings of pandq, meaning the set of joint distributions on X×Xwith respective marginals p\n",
      "andq. The product measure p⊗qis referred to as the trivial coupling, and the Wasserstein distance of order 1 is simply referred to\n",
      "as the Wasserstein distance.\n",
      "2.1 Denoising Diffusion Models\n",
      "Instead of employing the SDE framework, diffusion models are presented using the DDPM formulation with discrete-time processes.\n",
      "A diffusion model consists of two discrete-time stochastic processes: a forward process and a backward process. Both processes are\n",
      "indexed by time 0≤t≤T, where the number of time steps Tis a predetermined choice.\n",
      "**The forward process.** The forward process transforms a data point x0∼µinto a noise distribution q(xT|x0)through a sequence\n",
      "of conditional distributions q(xt|xt−1)for1≤t≤T. It is assumed that the forward process is defined such that for sufficiently\n",
      "large T, the distribution q(xT|x0)is close to a simple noise distribution p(xT), which is referred to as the prior distribution. For\n",
      "instance, p(xT) =N(xT; 0, I), the standard multivariate normal distribution, has been chosen in previous work.\n",
      "**The backward process.** The backward process is a Markov process with parametric transition kernels. The objective of the\n",
      "backward process is to perform the reverse operation of the forward process: transforming noise samples into (approximate) samples\n",
      "from the distribution µ. Following previous work, it is assumed that the backward process is defined by Gaussian distributions\n",
      "pθ(xt−1|xt)for2≤t≤Tas\n",
      "pθ(xt−1|xt) =N(xt−1;gθ\n",
      "t(xt), σ2\n",
      "tI),\n",
      "and\n",
      "pθ(x0|x1) =gθ\n",
      "1(x1),\n",
      "where the variance parameters σ2\n",
      "t∈R≥0are defined by a fixed schedule, the mean functions gθ\n",
      "t:RD→RDare learned using a\n",
      "neural network (with parameters θ) for2≤t≤T, andgθ\n",
      "1:RD→Xis a separate function dependent on σ1. In practice, the same\n",
      "network has been used for the functions gθ\n",
      "tfor2≤t≤T, and a separate discrete decoder for gθ\n",
      "1.\n",
      "2\n",
      "Generating new samples from a trained diffusion model is accomplished by sampling xt−1∼pθ(xt−1|xt)for1≤t≤T, starting\n",
      "from a noise vector xT∼p(xT)sampled from the prior p(xT).\n",
      "The following assumption is made regarding the backward process.\n",
      "**Assumption 1.** It is assumed that for each 1≤t≤T, there exists a constant Kθ\n",
      "t>0such that for every x1, x2∈X,\n",
      "||gθ\n",
      "t(x1)−gθ\n",
      "t(x2)|| ≤Kθ\n",
      "t||x1−x2||.\n",
      "In other words, gθ\n",
      "tisKθ\n",
      "t-Lipschitz continuous. This assumption is discussed in Remark 3.2.\n",
      "2.2 Additional Definitions\n",
      "The distribution πθ(·|x0)is defined as\n",
      "πθ(·|x0) =q(xT|x0)pθ(xT−1|xT)pθ(xT−2|xT−1). . . p θ(x1|x2)pθ(·|x1).\n",
      "Intuitively, for each x0∈X,πθ(·|x0)represents the distribution on Xobtained by reconstructing samples from q(xT|x0)through\n",
      "the backward process. Another way to interpret this distribution is that for any function f:X→R, the following equation holds:\n",
      "Eπθ(ˆx0|x0)[f(ˆx0)] =Eq(xT|x0)Epθ(xT−1|xT). . . E pθ(x1|x2)Epθ(ˆx0|x1)[f(ˆx0)].\n",
      "Given a finite set S={x1\n",
      "0, . . . , xn\n",
      "0}i.i.d.∼µ, the regenerated distribution is defined as the following mixture:\n",
      "µθ\n",
      "n=1\n",
      "nnX\n",
      "i=1πθ(·|xi\n",
      "0).\n",
      "This definition is analogous to the empirical regenerated distribution defined for V AEs. The distribution on Xlearned by the\n",
      "diffusion model is denoted as πθ(·)and defined as\n",
      "πθ(·) =p(xT)pθ(xT−1|xT)pθ(xT−2|xT−1). . . p θ(x1|x2)pθ(·|x1).\n",
      "In other words, for any function f:X→R, the expectation of fwith respect to πθ(·)is\n",
      "Eπθ(ˆx0)[f(ˆx0)] =Ep(xT)Epθ(xT−1|xT). . . E pθ(x1|x2)Epθ(ˆx0|x1)[f(ˆx0)].\n",
      "Hence, both πθ(·)andπθ(·|x0)are defined using the backward process, with the difference that πθ(·)starts with the prior\n",
      "p(xT) =N(xT; 0, I), while πθ(·|x0)starts with the noise distribution q(xT|x0).\n",
      "Finally, the loss function lθ:X×X→Ris defined as\n",
      "lθ(xT, x0) =Epθ(xT−1|xT)Epθ(xT−2|xT−1). . . E pθ(x1|x2)Epθ(ˆx0|x1)[||x0−ˆx0||].\n",
      "Hence, given a noise vector xTand a sample x0, the loss lθ(xT, x0)represents the average Euclidean distance between x0and any\n",
      "sample obtained by passing xTthrough the backward process.\n",
      "2.3 Our Approach\n",
      "The goal is to upper-bound the distance W1(µ, πθ(·)). Since the triangle inequality implies\n",
      "W1(µ, πθ(·))≤W1(µ, µθ\n",
      "n) +W1(µθ\n",
      "n, πθ(·)),\n",
      "the distance W1(µ, πθ(·))can be upper-bounded by upper-bounding the two expressions on the right-hand side separately. The\n",
      "upper bound on W1(µ, µθ\n",
      "n)is obtained using a straightforward adaptation of a proof. First, W1(µ, µθ\n",
      "n)is upper-bounded using the\n",
      "expectation of the loss function lθ, then the resulting expression is upper-bounded using a PAC-Bayesian-style expression dependent\n",
      "on the empirical risk and the prior-matching term.\n",
      "The upper bound on the second term W1(µθ\n",
      "n, πθ(·))uses the definition of µθ\n",
      "n. Intuitively, the difference between πθ(·|xi\n",
      "0)andπθ(·)\n",
      "is determined by the corresponding initial distributions: q(xT|xi\n",
      "0)andp(xT)forπθ(·). Hence, if the two initial distributions are\n",
      "close, and if the steps of the backward process are smooth (see Assumption 1), then πθ(·|xi\n",
      "0)andπθ(·)are close to each other.\n",
      "3\n",
      "3 Main Result\n",
      "3.1 Theorem Statement\n",
      "We are now ready to present the main result: a quantitative upper bound on the Wasserstein distance between the data-generating\n",
      "distribution µand the learned distribution πθ(·).\n",
      "**Theorem 3.1.** Assume the instance space Xhas finite diameter ∆ = supx,x′∈X||x−x′||<∞, and let λ >0andδ∈(0,1)be\n",
      "real numbers. Using the definitions and assumptions of the previous section, the following inequality holds with probability at least\n",
      "1−δover the random draw of S={x1\n",
      "0, . . . , xn\n",
      "0}i.i.d.∼µ:\n",
      "W1(µ, πθ(·))≤1\n",
      "nnX\n",
      "i=1Eq(xT|xi\n",
      "0)[lθ(xT, xi\n",
      "0)] +1\n",
      "λnnX\n",
      "i=1KL(q(xT|xi\n",
      "0)||p(xT)) +1\n",
      "λnlogn\n",
      "δ+λ∆2\n",
      "8n\n",
      "+ TY\n",
      "t=1Kθ\n",
      "t!\n",
      "Eq(xT|xi\n",
      "0)Ep(yT)[||xT−yT||]\n",
      "+TX\n",
      "t=2 t−1Y\n",
      "i=1Kθ\n",
      "i!\n",
      "σtEϵ,ϵ′[||ϵ−ϵ′||],\n",
      "where ϵ, ϵ′∼N(0, I)are standard Gaussian vectors.\n",
      "**Remark 3.1.** Before presenting the proof, let us discuss Theorem 3.1.\n",
      "* Because the right-hand side of the equation depends on a quantity computed using a finite i.i.d. sample S, the bound holds with\n",
      "high probability with respect to the randomness of S. This is the price we pay for having a quantitative upper bound with no\n",
      "exponential dependencies on problem parameters and no assumptions on the data-generating distribution µ. * The first term of the\n",
      "right-hand side is the average reconstruction loss computed over the sample S={x1\n",
      "0, . . . , xn\n",
      "0}. Note that for each 1≤i≤n, the\n",
      "expectation of lθ(xT|xi\n",
      "0)is only computed with respect to the noise distribution q(xT|xi\n",
      "0)defined by xi\n",
      "0itself. Hence, this term\n",
      "measures how well a noise vector xT∼q(xT|xi\n",
      "0)recovers the original sample xi\n",
      "0using the backward process, and averages over\n",
      "the set S={x1\n",
      "0, . . . , xn\n",
      "0}. * If the Lipschitz constants satisfy Kθ\n",
      "t<1for all 1≤t≤T, then the larger Tis, the smaller the upper\n",
      "bound gets. This is because the product of Kθ\n",
      "t’s then converges to 0. In Remark 3.2 below, we show that the assumption that Kθ\n",
      "t<1\n",
      "for all tis a quite reasonable one. * The hyperparameter λcontrols the trade-off between the prior-matching (KL) term and the\n",
      "diameter term ∆2. IfKθ\n",
      "t<1for all 1≤t≤TandT→ ∞ , then the convergence of the bound largely depends on the choice of λ.\n",
      "In that case, λ∝n1/2leads to faster convergence, while λ∝nleads to slower convergence to a smaller quantity. This is because\n",
      "the bound stems from PAC-Bayesian theory, where this trade-off is common. * The last term of the equation does not depend on the\n",
      "sample size n. Hence, the upper bound given by Theorem 3.1 does not converge to 0 as n→ ∞ . However, if the Lipschitz factors\n",
      "(Kθ\n",
      "t)1≤t≤Tare all less than 1, then this term can be very small, especially in low-dimensional spaces.\n",
      "3.2 Proof of the main theorem\n",
      "The following result is an adaptation of a previous result.\n",
      "**Lemma 3.2.** Let λ >0andδ∈(0,1)be real numbers. With probability at least 1−δover the randomness of the sample\n",
      "S={x1\n",
      "0, . . . , xn\n",
      "0}i.i.d.∼µ, the following holds:\n",
      "W1(µ, µθ\n",
      "n)≤1\n",
      "nnX\n",
      "i=1Eq(xT|xi\n",
      "0)[lθ(xT, xi\n",
      "0)] +1\n",
      "λnnX\n",
      "i=1KL(q(xT|xi\n",
      "0)||p(xT)) +1\n",
      "λnlogn\n",
      "δ+λ∆2\n",
      "8n.\n",
      "The proof of this result is a straightforward adaptation of a previous proof.\n",
      "Now, let us focus our attention on the second term of the right-hand side of the equation, namely W1(µθ\n",
      "n, πθ(·)). This part is trickier\n",
      "than for V AEs, for which the generative model’s distribution is simply a pushforward measure. Here, we have a non-deterministic\n",
      "sampling process with Tsteps.\n",
      "Assumption 1 leads to the following lemma on the backward process.\n",
      "**Lemma 3.3.** For any given x1, y1∈X, we have\n",
      "Epθ(x0|x1)Epθ(y0|y1)[||x0−y0||]≤Kθ\n",
      "1||x1−y1||.\n",
      "Moreover, if 2≤t≤T, then for any given xt, yt∈X, we have\n",
      "4\n",
      "Epθ(xt−1|xt)Epθ(yt−1|yt)[||xt−1−yt−1||]≤Kθ\n",
      "t||xt−yt||+σtEϵ,ϵ′[||ϵ−ϵ′||],\n",
      "where ϵ, ϵ′∼N(0, I), meaning Eϵ,ϵ′is a shorthand for Eϵ,ϵ′∼N(0,I).\n",
      "**Proof.** For the first part, let x1, y1∈X. Since according to the equation pθ(x0|x1) =δgθ\n",
      "1(x1)(x0)andpθ(y0|y1) =δgθ\n",
      "1(y1)(y0),\n",
      "then\n",
      "Epθ(x0|x1)Epθ(y0|y1)[||x0−y0||] =||gθ\n",
      "1(x1)−gθ\n",
      "1(y1)|| ≤Kθ\n",
      "1||x1−y1||.\n",
      "For the second part, let 2≤t≤Tandxt, yt∈X. Since pθ(xt−1|xt) =N(xt−1;gθ\n",
      "t(xt), σ2\n",
      "tI), the reparameterization trick implies\n",
      "that sampling xt−1∼pθ(xt−1|xt)is equivalent to setting\n",
      "xt−1=gθ\n",
      "t(xt) +σtϵt,withϵt∼N(0, I).\n",
      "Using the above equation, the triangle inequality, and Assumption 1, we obtain\n",
      "Epθ(xt−1|xt)Epθ(yt−1|yt)[||xt−1−yt−1||]\n",
      "=Eϵt,ϵ′\n",
      "t∼N(0,I)[||gθ\n",
      "t(xt) +σtϵt−gθ\n",
      "t(yt)−σtϵ′\n",
      "t||]\n",
      "≤Eϵt,ϵ′\n",
      "t∼N(0,I)[||gθ\n",
      "t(xt)−gθ\n",
      "t(yt)||] +σtEϵt,ϵ′\n",
      "t∼N(0,I)[||ϵt−ϵ′\n",
      "t||]\n",
      "≤Kθ\n",
      "t||xt−yt||+σtEϵ,ϵ′[||ϵ−ϵ′||],\n",
      "where ϵ, ϵ′∼N(0, I).\n",
      "Next, we can use the inequalities of Lemma 3.3 to prove the following result.\n",
      "**Lemma 3.4.** Let T≥1. The following inequality holds:\n",
      "Epθ(xT−1|xT)Epθ(yT−1|yT)Epθ(xT−2|xT−1)Epθ(yT−2|yT−1). . . E pθ(x0|x1)Epθ(y0|y1)[||x0−y0||]\n",
      "≤ TY\n",
      "t=1Kθ\n",
      "t!\n",
      "||xT−yT||+TX\n",
      "t=2 t−1Y\n",
      "i=1Kθ\n",
      "i!\n",
      "σtEϵ,ϵ′[||ϵ−ϵ′||],\n",
      "where ϵ, ϵ′∼N(0, I).\n",
      "**Proof Idea.** Lemma 3.4 is proven by induction using Lemma 3.3 in the induction step.\n",
      "Using the two previous lemmas, we obtain the following upper bound on W1(µθ\n",
      "n, πθ(·)).\n",
      "**Lemma 3.5.** The following inequality holds:\n",
      "W1(µθ\n",
      "n, πθ(·))≤1\n",
      "nnX\n",
      "i=1 TY\n",
      "t=1Kθ\n",
      "t!\n",
      "Eq(xT|xi\n",
      "0)Ep(yT)[||xT−yT||] +TX\n",
      "t=2 t−1Y\n",
      "i=1Kθ\n",
      "i!\n",
      "σtEϵ,ϵ′[||ϵ−ϵ′||],\n",
      "where ϵ, ϵ′∼N(0, I).\n",
      "**Proof.** Using the definition of W1, the trivial coupling, the definitions of µθ\n",
      "nandπθ(·), and Lemma 3.4, we get the desired result.\n",
      "Combining Lemmas 3.2 and 3.5 with the triangle inequality yields Theorem 3.1.\n",
      "3.3 Special case using the forward process of Ho et al. (2020)\n",
      "Theorem 3.1 establishes a general upper bound that holds for any forward process, as long as the backward process satisfies\n",
      "Assumption 1. In this section, we specialize the statement of the theorem to the particular case of the forward process defined in\n",
      "previous work.\n",
      "LetX⊆RD. The forward process is a Gauss-Markov process with transition densities defined as\n",
      "q(xt|xt−1) =N(xt;√αtxt−1,(1−αt)I),\n",
      "where α1, . . . , α Tis a fixed noise schedule such that 0< αt<1for all t. This definition implies that at each time step 1≤t≤T,\n",
      "5\n",
      "q(xt|x0) =N(xt;√¯αtx0,(1−¯αt)I),with¯αt=tY\n",
      "i=1αi.\n",
      "The optimization objective to train the backward process ensures that for each time step t, the distribution pθ(xt−1|xt)remains close\n",
      "to the ground-truth distribution q(xt−1|xt, x0)given by\n",
      "q(xt−1|xt, x0) =N(xt−1; ˜µq\n",
      "t(xt, x0),˜σ2\n",
      "tI),\n",
      "where\n",
      "˜µq\n",
      "t(xt, x0) =√αt(1−¯αt−1)\n",
      "1−¯αtxt+√¯αt−1(1−αt)\n",
      "1−¯αtx0.\n",
      "Now, we discuss Assumption 1 under these definitions.\n",
      "**Remark 3.2.** We can get a glimpse at the range of Kθ\n",
      "tfor a trained DDPM by looking at the distribution q(xt−1|xt, x0), since\n",
      "pθ(xt−1|xt)is optimized to be as close as possible to q(xt−1|xt, x0).\n",
      "For a given x0∼µ, let us take a look at the Lipschitz norm of x7→˜µq\n",
      "t(x, x0). Using the above equation, we have\n",
      "˜µq\n",
      "t(xt, x0)−˜µq\n",
      "t(yt, x0) =√αt(1−¯αt−1)\n",
      "1−¯αt(xt−yt).\n",
      "Hence, x7→˜µq\n",
      "t(x, x0)isK′\n",
      "t-Lipschitz continuous with\n",
      "K′\n",
      "t=√αt(1−¯αt−1)\n",
      "1−¯αt.\n",
      "Now, if αt<1for all 1≤t≤T, then we have 1−¯αt>1−¯αt−1, which implies K′\n",
      "t<1for all 1≤t≤T.\n",
      "Remark 3.2 shows that the Lipschitz norm of the mean function ˜µq\n",
      "t(·, x0)does not depend on x0. Indeed, looking at the previous\n",
      "equation, we can see that for any initial x0, the Lipschitz norm K′\n",
      "t=√αt(1−¯αt−1)\n",
      "1−¯αtonly depends on the noise schedule, not x0itself.\n",
      "Since gθ\n",
      "t(·, x0)is optimized to match ˜µq\n",
      "t(·, x0)for each x0in the training set, and all the functions ˜µq\n",
      "t(·, x0)have the same Lipschitz\n",
      "norm K′\n",
      "t, we believe it is reasonable to assume gθ\n",
      "tis Lipschitz continuous as well. This is the intuition behind Assumption 1.\n",
      "**The prior-matching term.** With the definitions of this section, the prior matching term KL(q(xT|x0)||p(xT))has the following\n",
      "closed form:\n",
      "KL(q(xT|x0)||p(xT)) =1\n",
      "2\u0002\n",
      "−Dlog(1−¯αT)−D¯αT+ ¯αT||x0||2\u0003\n",
      ".\n",
      "**Upper-bounds on the average distance between Gaussian vectors.** If ϵ, ϵ′are D-dimensional vectors sampled from N(0, I), then\n",
      "Eϵ,ϵ′[||ϵ−ϵ′||]≤√\n",
      "2D.\n",
      "Moreover, since q(xT|x0) =N(xT;√¯αTx0,(1−¯αT)I)and the prior p(yT) =N(yT; 0, I),\n",
      "Eq(xT|x0)Ep(yT)[||xT−yT||]≤p\n",
      "¯αT||x0||2+ (2−¯αT)D.\n",
      "**Special case of the main theorem.** With the definitions of this section, the inequality of Theorem 3.1 implies that with probability\n",
      "at least 1−δover the randomness of {x1\n",
      "0, . . . , x\n",
      "6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file using PyPDF2.\n",
    "    :param file_path: Path to the PDF file.\n",
    "    :return: Extracted text as a single string.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"  # Extract text page by page\n",
    "    return text\n",
    "\n",
    "# File path\n",
    "file_path = \"../Dataset/Reference/Publishable/TMLR/R015.pdf\"\n",
    "\n",
    "# Extract text from PDF\n",
    "pdf_text = extract_text_from_pdf(file_path)\n",
    "\n",
    "# Display the extracted text\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 799\n",
      "\n",
      "Abstract:\n",
      " tive models, particularly diffusion models, are a significant family within deep learning. This study\n",
      "provides a precise upper limit for the Wasserstein distance between a learned distribution by a diffusion model\n",
      "and the target distribution. In contrast to earlier research, this analysis does not rely on presumptions regarding\n",
      "the learned score function. Furthermore, the findings are applicable to any data-generating distributions within\n",
      "restricted instance spaces, even those lacking a density relative to the Lebesgue measure, and the upper limit is not\n",
      "exponentially dependent on the ambient space dimension. The primary finding expands upon recent research by\n",
      "Mbacke et al. (\n"
     ]
    }
   ],
   "source": [
    "def extract_abstract(pdf_text):\n",
    "    \"\"\"\n",
    "    Extract the title and abstract dynamically from the PDF text.\n",
    "    Title: From the start to \"Abstract\".\n",
    "    Abstract: From \"Abstract\" to \"Introduction\".\n",
    "    \"\"\"\n",
    "    abstract = \"\", \"\"\n",
    "    try:\n",
    "        # Extract Abstract\n",
    "        abstract_start_idx = pdf_text.index(\"Abstract\") + len(\"Abstract\") + len(\"Introdcution\")\n",
    "        abstract_end_idx = pdf_text.index(\"2\")\n",
    "        print(abstract_start_idx, abstract_end_idx)\n",
    "        abstract = pdf_text[abstract_start_idx:abstract_end_idx].strip()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error extracting title and abstract: {e}\")\n",
    "    \n",
    "    return abstract\n",
    "\n",
    "abstract = extract_abstract(pdf_text)\n",
    "\n",
    "print(\"\\nAbstract:\\n\", abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('diffusion', np.float64(0.22941573387056174)),\n",
      " ('distribution', np.float64(0.22941573387056174)),\n",
      " ('learned', np.float64(0.22941573387056174)),\n",
      " ('limit', np.float64(0.22941573387056174)),\n",
      " ('models', np.float64(0.22941573387056174)),\n",
      " ('research', np.float64(0.22941573387056174)),\n",
      " ('upper', np.float64(0.22941573387056174)),\n",
      " ('al', np.float64(0.11470786693528087)),\n",
      " ('ambient', np.float64(0.11470786693528087)),\n",
      " ('analysis', np.float64(0.11470786693528087)),\n",
      " ('applicable', np.float64(0.11470786693528087)),\n",
      " ('contrast', np.float64(0.11470786693528087)),\n",
      " ('data', np.float64(0.11470786693528087)),\n",
      " ('deep', np.float64(0.11470786693528087)),\n",
      " ('density', np.float64(0.11470786693528087)),\n",
      " ('dependent', np.float64(0.11470786693528087)),\n",
      " ('dimension', np.float64(0.11470786693528087)),\n",
      " ('distance', np.float64(0.11470786693528087)),\n",
      " ('distributions', np.float64(0.11470786693528087)),\n",
      " ('does', np.float64(0.11470786693528087)),\n",
      " ('earlier', np.float64(0.11470786693528087)),\n",
      " ('et', np.float64(0.11470786693528087)),\n",
      " ('expands', np.float64(0.11470786693528087)),\n",
      " ('exponentially', np.float64(0.11470786693528087)),\n",
      " ('family', np.float64(0.11470786693528087)),\n",
      " ('finding', np.float64(0.11470786693528087)),\n",
      " ('findings', np.float64(0.11470786693528087)),\n",
      " ('function', np.float64(0.11470786693528087)),\n",
      " ('furthermore', np.float64(0.11470786693528087)),\n",
      " ('generating', np.float64(0.11470786693528087)),\n",
      " ('instance', np.float64(0.11470786693528087)),\n",
      " ('lacking', np.float64(0.11470786693528087)),\n",
      " ('learning', np.float64(0.11470786693528087)),\n",
      " ('lebesgue', np.float64(0.11470786693528087)),\n",
      " ('mbacke', np.float64(0.11470786693528087)),\n",
      " ('measure', np.float64(0.11470786693528087)),\n",
      " ('model', np.float64(0.11470786693528087)),\n",
      " ('particularly', np.float64(0.11470786693528087)),\n",
      " ('precise', np.float64(0.11470786693528087)),\n",
      " ('presumptions', np.float64(0.11470786693528087)),\n",
      " ('primary', np.float64(0.11470786693528087)),\n",
      " ('provides', np.float64(0.11470786693528087)),\n",
      " ('recent', np.float64(0.11470786693528087)),\n",
      " ('regarding', np.float64(0.11470786693528087)),\n",
      " ('relative', np.float64(0.11470786693528087)),\n",
      " ('rely', np.float64(0.11470786693528087)),\n",
      " ('restricted', np.float64(0.11470786693528087)),\n",
      " ('score', np.float64(0.11470786693528087)),\n",
      " ('significant', np.float64(0.11470786693528087)),\n",
      " ('space', np.float64(0.11470786693528087)),\n",
      " ('spaces', np.float64(0.11470786693528087)),\n",
      " ('study', np.float64(0.11470786693528087)),\n",
      " ('target', np.float64(0.11470786693528087)),\n",
      " ('tive', np.float64(0.11470786693528087)),\n",
      " ('wasserstein', np.float64(0.11470786693528087))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample paragraph\n",
    "paragraph = \"Python is a versatile programming language. It is widely used in web development, data science, and machine learning.\"\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform([abstract])\n",
    "\n",
    "# Extract keywords and their scores\n",
    "scores = zip(vectorizer.get_feature_names_out(), X.toarray()[0])\n",
    "sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Top keywords\n",
    "keywords = sorted_scores  # Adjust the number as needed\n",
    "from pprint import pprint\n",
    "pprint(sorted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDD_KEYWORDS = [\n",
    "    \"data cleaning\",\n",
    "    \"preparation\",\n",
    "    \"data transformation\",\n",
    "    \"mining\",\n",
    "    \"scalability\",\n",
    "    \"explainability\",\n",
    "    \"data privacy\"\n",
    "]\n",
    "\n",
    "CVPR_KEYWORDS = [\n",
    "    \"image\",\n",
    "    \"3d\",\n",
    "    \"detection\",\n",
    "    \"video\",\n",
    "    \"segmentation\",\n",
    "    \"transformer\",\n",
    "    \"representation\",\n",
    "    \"generation\",\n",
    "    \"diffusion\",\n",
    "]\n",
    "\n",
    "TMLR_KEYWORDS = [\n",
    "    \"Statistical Learning Theory\",\n",
    "    \"Optimization Algorithms\",\n",
    "    \"Generalization\",\n",
    "    \"Adversarial Robustness\",\n",
    "    \"Kernel Methods\",\n",
    "    \"Probabilistic Graphical Models\",\n",
    "    \"Bayesian Inference\",\n",
    "    \"Computational Efficiency\",\n",
    "    \"Ethics\",\n",
    "    \"Fairness\",\n",
    "    \"Policy Implications\",\n",
    "    \"Benchmarking Studies\",\n",
    "    \"Responsible\"\n",
    "]\n",
    "\n",
    "NEURIPS_KEYWORDS = [\n",
    "    \"Deep Learning Architectures\",\n",
    "    \"Transformers\",\n",
    "    \"Diffusion Models\",\n",
    "    \"Multimodal Networks\",\n",
    "    \"Neuroscience-Inspired Models\",\n",
    "    \"Non-Convex Optimization\",\n",
    "    \"Differential Privacy\",\n",
    "]\n",
    "\n",
    "EMNLP_KEYWORDS = [\n",
    "    \"Natural Language Understanding\",\n",
    "    \"Natural Language Generation\",\n",
    "    \"Machine Translation\",\n",
    "    \"Speech-to-Text\",\n",
    "    \"Sentiment Analysis\",\n",
    "    \"Question Answering\",\n",
    "    \"Dialogue Systems\",\n",
    "    \"Information Retrieval\",\n",
    "    \"Summarization\",\n",
    "    \"Text Classification\",\n",
    "    \"Entity Recognition\"\n",
    "    \"semantic parsing\",\n",
    "    \"semantic classification\",\n",
    "    \"natural language toolkit\",\n",
    "    \"shallow parsing\",\n",
    "    \"ambiguous language\",\n",
    "    \"pragmatic language\",\n",
    "    \"morphological language\",\n",
    "    \"chunking\",\n",
    "    \"syntax processing\",\n",
    "    \"role labeling\",\n",
    "    \"textual entailment\",\n",
    "    \"word sense disambiguation\",\n",
    "    \"discourse analysis\",\n",
    "    \"information extraction\",\n",
    "    \"corereference resolution\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword matching in the abstract of papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Conference: TMLR\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Keywords for each conference\n",
    "keywords = {\n",
    "    \"KDD\": KDD_KEYWORDS,\n",
    "    \"CVPR\": CVPR_KEYWORDS,\n",
    "    \"TMLR\": NEURIPS_KEYWORDS,\n",
    "    \"NEURIPS\": TMLR_KEYWORDS,\n",
    "    \"EMNLP\": EMNLP_KEYWORDS\n",
    "}\n",
    "\n",
    "# Extracted keywords\n",
    "extracted_keywords = [keyword for keyword, score in sorted_scores]\n",
    "\n",
    "# Create a list of documents (one per conference) and the extracted keywords\n",
    "documents = [' '.join(conf_keywords) for conf_keywords in keywords.values()]\n",
    "documents.append(' '.join(extracted_keywords))\n",
    "\n",
    "# Compute the vectorized representation of the keywords\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Compute cosine similarity between the extracted keywords vector and each conference vector\n",
    "similarities = cosine_similarity(vectors[-1], vectors[:-1])\n",
    "\n",
    "# Find the conference with the highest cosine similarity\n",
    "conference = list(keywords.keys())[similarities.argmax()]\n",
    "\n",
    "print(f\"Predicted Conference: {conference}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
